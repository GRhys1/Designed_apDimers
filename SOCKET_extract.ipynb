{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seqlogo #This package can be found in the Conda repository bioconda/packages/seqlogo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_directory = os.fsencode('./all_ap_dimersfiles/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_residues2(knob_residues, dictionary_residtoheptad):\n",
    "\n",
    "    \"\"\"Takes all lines that include information about knob residues and returns two dictionaries one for a and one for d\n",
    "    knobs where the values contain lists. Within lists the first entry is a knob and subsequent four hole residues are as follows:\n",
    "    a =  aNterm, d, e, aCterm\n",
    "    d = dNterm, g, a, dCterm\"\"\"\n",
    "\n",
    "    one_letter_code = {'A':'ALA','C':'CYS','D':'ASP','E':'GLU','F':'PHE','G':'GLY','H':'HIS','I':'ILE','K':'LYS',\n",
    "                        'L':'LEU','M':'MET','N':'ASN','P':'PRO','Q':'GLN','R':'ARG','S':'SER','T':'THR','V':'VAL'               \n",
    "                        ,'W':'TRP','Y':'TYR'}\n",
    "\n",
    "    three_letter_code = {'ALA':'A','CYS':'C','ASP':'D','GLU':'E','PHE':'F','GLY':'G','HIS':'H','ILE':'I','LYS':'K',\n",
    "                        'LEU':'L','MET':'M','ASN':'N','PRO':'P','GLN':'Q','ARG':'R','SER':'S','THR':'T','VAL':'V'               \n",
    "                        ,'TRP':'W','TYR':'Y'}\n",
    "\n",
    "    all_knobs = []\n",
    "    for knob_residue_line in knob_residues:\n",
    "        #this section splits and formats a line: remove brackets, colons, commas and new line characters \n",
    "        split_line = re.split(' ',knob_residue_line)\n",
    "        split_line_nochar = []\n",
    "        for x in split_line: \n",
    "            split_line_nochar.append(x.replace(')','').replace('(','').replace(':','').replace(',','').replace('\\n',''))\n",
    "        #this extracts each knob residue and hole residues as residuenumber_chainletter in a list\n",
    "        one_knob_entry = []\n",
    "        aa_counter = 1\n",
    "        translate_counter = 1\n",
    "        for x in split_line_nochar:\n",
    "            if x[-2:-1].isdigit() and not x[-1:].isdigit() and translate_counter==1:\n",
    "                one_knob_entry.append(x)\n",
    "                translate_counter += 1\n",
    "            elif x in three_letter_code and aa_counter ==1:\n",
    "                aa_counter += 1\n",
    "            elif x in three_letter_code:\n",
    "                one_knob_entry.append(three_letter_code[x])\n",
    "            else:\n",
    "                pass\n",
    "        all_knobs.append(one_knob_entry)\n",
    "    #translate knoblist takes residuenumber_chainletter and coverts to amino acid and heptad position\n",
    "    #it also filters out knob residues and holes that contain non-canonical amino acids\n",
    "    translate_knoblist = []\n",
    "    for knob_entry in all_knobs:\n",
    "        if knob_entry[0] not in dict_residtohept:\n",
    "            pass\n",
    "        elif len(knob_entry) != 5:\n",
    "            pass\n",
    "        else:\n",
    "            translated_knob_entry = []\n",
    "            for individual_residue in knob_entry:\n",
    "                if individual_residue not in dict_residtohept:\n",
    "                    translated_knob_entry.append(individual_residue)\n",
    "                else:\n",
    "                    translated_knob_entry.append(dict_residtohept[individual_residue])\n",
    "            translate_knoblist.append(translated_knob_entry)\n",
    "\n",
    "    a_residues = {}\n",
    "    d_residues = {}\n",
    "    a_counter = 1\n",
    "    d_counter = 1\n",
    "    for KIH_info in translate_knoblist:\n",
    "        if KIH_info[0][1] == 'a':\n",
    "            a_residues['a'+str(a_counter)]=[x[0] for x in KIH_info]\n",
    "            a_counter +=1\n",
    "        if KIH_info[0][1] == 'd':\n",
    "            d_residues['d'+str(d_counter)]=[x[0] for x in KIH_info]\n",
    "            d_counter +=1\n",
    "    return a_residues, d_residues\n",
    "\n",
    "def dictionary_residtoheptad2(helices_info):\n",
    "    \"\"\"iterate through lines of socket output to generate a dictionary with residuenumber_chainname as key and\n",
    "    a list of amino acid and heptad position as output\"\"\"\n",
    "    helix_info_dict = {}\n",
    "    for line in helices_info:\n",
    "        if line[0:6] == 'assign':\n",
    "            a = [int(s) for s in re.split('-| |:',line) if s.isdigit()]\n",
    "            a = a[1:3]\n",
    "            chain_name = line[-2:-1]\n",
    "        elif line[0:6] == 'sequen':\n",
    "            sequence = line[9:-1]\n",
    "        elif line[0:6] == 'regist':\n",
    "            register = line[9:-1]\n",
    "            character_number = 0\n",
    "            for sequence_value, register_value in zip(sequence,register):\n",
    "                #This is to catch PDB files that start with negative numbers, those that cannot be resolved by this\n",
    "                #are numbered from 1 onwards and will not match when called by get_residues() and subsequently\n",
    "                #will be discarded.\n",
    "                if len(range(a[0],a[1]+1)) == len(sequence):\n",
    "                    residue_number = range(a[0],a[1]+1)[character_number]\n",
    "                elif len(range(-1*a[0],a[1]+1)) == len(sequence):\n",
    "                    residue_number = range(-1*a[0],a[1]+1)[character_number]\n",
    "                else:\n",
    "                    residue_number = 'xxx'\n",
    "                helix_info_dict[str(residue_number)+chain_name]=[sequence_value,register_value]\n",
    "                character_number += 1\n",
    "        else:\n",
    "             pass\n",
    "    return helix_info_dict\n",
    "\n",
    "def CountFrequency(my_list): \n",
    "      \n",
    "    # Creating an empty dictionary  \n",
    "    freq = {} \n",
    "    for items in my_list: \n",
    "        freq[items] = my_list.count(items) \n",
    "     \n",
    "    return freq\n",
    "\n",
    "def convert_to_probability(array_all):\n",
    "    array_all_outof1 = {}\n",
    "    total_sum = {}\n",
    "    #Converts each row to a total of 1\n",
    "    for complete_entry in array_all:\n",
    "        frequence_array = np.zeros((4,20))\n",
    "        row_number = 0\n",
    "        for row in array_all[complete_entry]:\n",
    "            divide_by = np.ones(20)*np.sum(row)\n",
    "            frequency_row = np.true_divide(row, divide_by, out=np.zeros_like(row), where=divide_by!=0)\n",
    "            frequence_array[row_number]= frequency_row\n",
    "            row_number += 1\n",
    "        total_sum[complete_entry]=divide_by[0]\n",
    "        array_all_outof1[complete_entry]=frequence_array\n",
    "\n",
    "    return array_all_outof1, total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Execute code to get the two (a & d knob residues) dictionaries\n",
    "all_a_dictionary = {}\n",
    "all_d_dictionary = {}\n",
    "for socket_file in sorted(os.listdir(import_directory)):\n",
    "    filename = os.fsdecode(socket_file)\n",
    "    directory = os.fsdecode(import_directory)\n",
    "    if os.path.isfile(directory+filename) and not filename.startswith('.') :\n",
    "        with open(directory+filename, 'r') as socket_output:\n",
    "                ##numbering will differ from input as blank lines are stripped\n",
    "                socket_lines = [line for line in socket_output.readlines() if line.strip()]\n",
    "                ##extract lines that record knob residues\n",
    "                knob_residues = []\n",
    "                for line in socket_lines:\n",
    "                    if len(re.split(' ',line)[0]) < 2:\n",
    "                        pass\n",
    "                    elif re.split(' ',line)[0][-2].isdigit() and re.split(' ',line)[0][-1] == ')':\n",
    "                        knob_residues.append(line)\n",
    "                #get lines that will identify heptad position on helix\n",
    "                helices_info = [x for x in socket_lines if x[0:6] == 'assign' or x[0:6] == 'sequen' or x[0:6] == 'regist'] \n",
    "                dict_residtohept = dictionary_residtoheptad2(helices_info)\n",
    "                a_dictionary, d_dictionary = get_residues2(knob_residues, dict_residtohept)\n",
    "        all_a_dictionary[filename[0:4]]=a_dictionary\n",
    "        all_d_dictionary[filename[0:4]]=d_dictionary\n",
    "        socket_output.close\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run to quantify the number of pdb files used and the number of KIH interactions extracted\n",
    "empty_a = []\n",
    "for x in all_a_dictionary:\n",
    "    if len(all_a_dictionary[x]) == 0:\n",
    "        empty_a.append(x)\n",
    "\n",
    "empty_d = []\n",
    "for x in all_d_dictionary:\n",
    "    if len(all_a_dictionary[x]) == 0:\n",
    "        empty_d.append(x)\n",
    "\n",
    "print('There are ' + str(len(empty_a)) + \" pdfiles that don't contain KIH entries from the complete set of \" + str(len(all_a_dictionary))\n",
    "     + \" (print empty_a or empty_d to get a list of the empty entries).\")\n",
    "counter_a = 0\n",
    "counter_d = 0\n",
    "for x in all_a_dictionary:\n",
    "    for y in all_a_dictionary[x]:\n",
    "        counter_a += 1\n",
    "for x in all_d_dictionary:\n",
    "    for y in all_d_dictionary[x]:\n",
    "        counter_d += 1\n",
    "print(\"From the combined set there are \" + str(counter_a) + \" KIH entries for a positions and \" + str(counter_d) +\n",
    "      \" KIH entries for d postions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this code to quickly identify pdb files that have a specific hole residue motif\n",
    "#  [0,1,2,3,4]  a =  aNterm, d, e, aCterm\n",
    "#  [0,1,2,3,4]  d = dNterm, g, a, dCterm\n",
    "\n",
    "all_pdbs_match = {}\n",
    "for entry in all_a_dictionary:\n",
    "    for hole in all_a_dictionary[entry]:\n",
    "        if all_a_dictionary[entry][hole][0] == 'A' and all_a_dictionary[entry][hole][3] == 'E':\n",
    "            all_pdbs_match[entry]='x'\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The following cells are used to produce frequencies from the data.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate two dictionaries for a and d knob residues (a_positions and d_positions). \n",
    "#Keys represent the amino acid identity and the values is a nested dictionary where values represent \n",
    "#a running total of knob residues and values are lists of knob and hole single-letter-code amino acids\n",
    "\n",
    "one_letter_code = {'A':'ALA','C':'CYS','D':'ASP','E':'GLU','F':'PHE','G':'GLY','H':'HIS','I':'ILE','K':'LYS',\n",
    "                    'L':'LEU','M':'MET','N':'ASN','P':'PRO','Q':'GLN','R':'ARG','S':'SER','T':'THR','V':'VAL'               \n",
    "                    ,'W':'TRP','Y':'TYR'}\n",
    "\n",
    "three_letter_code = {'ALA':'A','CYS':'C','ASP':'D','GLU':'E','PHE':'F','GLY':'G','HIS':'H','ILE':'I','LYS':'K',\n",
    "                    'LEU':'L','MET':'M','ASN':'N','PRO':'P','GLN':'Q','ARG':'R','SER':'S','THR':'T','VAL':'V'               \n",
    "                    ,'TRP':'W','TYR':'Y'}\n",
    "\n",
    "a_positions = {'ALA':{}, 'CYS':{}, 'ASP':{}, 'GLU':{}, 'PHE':{}, 'GLY':{}, 'HIS':{}, 'ILE':{}, 'LYS':{}, \n",
    "               'LEU':{}, 'MET':{}, 'ASN':{}, 'PRO':{}, 'GLN':{}, 'ARG':{}, 'SER':{}, 'THR':{}, 'VAL':{}, \n",
    "               'TRP':{}, 'TYR':{}}\n",
    "\n",
    "d_positions = {'ALA':{}, 'CYS':{}, 'ASP':{}, 'GLU':{}, 'PHE':{}, 'GLY':{}, 'HIS':{}, 'ILE':{}, 'LYS':{}, \n",
    "               'LEU':{}, 'MET':{}, 'ASN':{}, 'PRO':{}, 'GLN':{}, 'ARG':{}, 'SER':{}, 'THR':{}, 'VAL':{}, \n",
    "               'TRP':{}, 'TYR':{}}\n",
    "\n",
    "\n",
    "number_of_entries = 0\n",
    "number_of_knobs = 0\n",
    "\n",
    "for pdb_code, knoblist in all_a_dictionary.items():\n",
    "    number_of_entries += 1\n",
    "    for number , KIH in knoblist.items():\n",
    "        a_positions[one_letter_code[KIH[0]]].update({'a'+str(number_of_knobs): KIH})\n",
    "        number_of_knobs += 1\n",
    "\n",
    "number_of_entries = 0\n",
    "number_of_knobs = 0\n",
    "        \n",
    "for pdb_code, knoblist in all_d_dictionary.items():\n",
    "    number_of_entries += 1\n",
    "    for number , KIH in knoblist.items():\n",
    "        d_positions[one_letter_code[KIH[0]]].update({'d'+str(number_of_knobs): KIH})\n",
    "        number_of_knobs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a =  aNterm, d, e, aCterm\n",
    "#d = dNterm, g, a, dCterm\n",
    "frequency_dictionary = {} \n",
    "for aa in a_positions:\n",
    "    \n",
    "    all_positions = {'aN':[], 'd':[], 'e':[], 'aC':[], 'dN':[], 'g':[], 'a':[], 'dC':[]} \n",
    "    aa_a_position = list(a_positions[aa].values())\n",
    "    aa_d_position = list(d_positions[aa].values())\n",
    "    \n",
    "    for x in aa_a_position:\n",
    "        all_positions['aN'].append(x[1])\n",
    "        all_positions['d'].append(x[2])\n",
    "        all_positions['e'].append(x[3])\n",
    "        all_positions['aC'].append(x[4])\n",
    "\n",
    "    for x in aa_d_position:\n",
    "        all_positions['dN'].append(x[1])\n",
    "        all_positions['g'].append(x[2])\n",
    "        all_positions['a'].append(x[3])\n",
    "        all_positions['dC'].append(x[4])\n",
    "    \n",
    "    for position in all_positions:\n",
    "        frequency_dictionary[aa+'_'+position]=CountFrequency(all_positions[position])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make arrays from dictionary of data. Such that each column represents the canonical amino acids organised alphabetically\n",
    "#and the rows represent the hole positions.\n",
    "\n",
    "array_all_a = {}\n",
    "array_all_d = {}\n",
    "a_holepositions = ['aN', 'd', 'e', 'aC']\n",
    "d_holepositions = ['dN', 'g', 'a', 'dC']\n",
    "one_letter_code_list = sorted(list(one_letter_code))\n",
    "for x in list(three_letter_code.keys()):\n",
    "    empty_array = np.zeros((4,20))\n",
    "    position_counter = 0\n",
    "    for pos in a_holepositions:\n",
    "        if x+\"_\"+pos in frequency_dictionary:\n",
    "            aminoacid_counter = 0\n",
    "            for g in one_letter_code_list:\n",
    "                if g in frequency_dictionary[x+\"_\"+pos]:\n",
    "                    empty_array[position_counter,aminoacid_counter]=frequency_dictionary[x+\"_\"+pos][g]\n",
    "                    aminoacid_counter +=1\n",
    "                else:\n",
    "                    aminoacid_counter +=1\n",
    "        position_counter +=1\n",
    "    array_all_a[x]=empty_array\n",
    "\n",
    "for x in list(three_letter_code.keys()):\n",
    "    ay = np.zeros((4,20))\n",
    "    position_counter = 0\n",
    "    for pos in d_holepositions:\n",
    "        if x+\"_\"+pos in frequency_dictionary:\n",
    "            aminoacid_counter = 0\n",
    "            for g in one_letter_code_list:\n",
    "                if g in frequency_dictionary[x+\"_\"+pos]:\n",
    "                    ay[position_counter,aminoacid_counter]=frequency_dictionary[x+\"_\"+pos][g]\n",
    "                    aminoacid_counter +=1\n",
    "                else:\n",
    "                    aminoacid_counter +=1\n",
    "        position_counter +=1\n",
    "    array_all_d[x]=ay     \n",
    "\n",
    "array_all_a_outof1, array_all_a_outof1_sum = convert_to_probability(array_all_a)\n",
    "array_all_d_outof1, array_all_d_outof1_sum = convert_to_probability(array_all_d)\n",
    "a_total = sum([int(x) for x in array_all_a_outof1_sum.values()])\n",
    "d_total = sum([int(x) for x in array_all_d_outof1_sum.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Execute code to quickly check frequency of knob residues\n",
    "for key, value in sorted(array_all_a_outof1_sum.items(), key=lambda item: item[1]):\n",
    "    print(\"%s: %s\" % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute code to output all frequencies into csv files\n",
    "csv_dir = \"./frequency_csv/\"\n",
    "for residue in array_all_d_outof1.keys():\n",
    "    DF = pd.DataFrame(array_all_d_outof1[residue], columns = list(array_all_d_outof1.keys()))\n",
    "    DF = DF.transpose()\n",
    "    DF.columns= d_holepositions\n",
    "    DF.to_csv(csv_dir+\"d_positions_\"+residue+\".csv\")\n",
    "for residue in array_all_a_outof1.keys():\n",
    "    DF = pd.DataFrame(array_all_a_outof1[residue], columns = list(array_all_a_outof1.keys()))\n",
    "    DF = DF.transpose()\n",
    "    DF.columns= a_holepositions\n",
    "    DF.to_csv(csv_dir+\"a_positions_\"+residue+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The following cells allow the frequency data to be plotted as Sequence Logos.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ./all_ap_dimers_seqlog/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Sequence logos from frequency data\n",
    "\n",
    "for residue in array_all_a_outof1:\n",
    "    #file = open(residue+\"_aposition_\"+str(array_all_a_outof1_sum[residue])+\".png\",\"wb\") \n",
    "    if np.sum(array_all_a_outof1[residue][0]) == 0.0:\n",
    "        pass\n",
    "    else:\n",
    "        aa = seqlogo.Ppm(array_all_a_outof1[residue], alphabet_type=\"AA\")\n",
    "        filename = str(residue)+\"_aposition_\"+str(array_all_a_outof1_sum[residue])+\".png\"\n",
    "        seqlogo.seqlogo(aa, ic_scale = False, format = 'png', size = 'medium', color_scheme='chemistry', \n",
    "            filename=filename, xaxis=True)\n",
    "        \n",
    "for residue in array_all_d_outof1:\n",
    "    #file = open(residue+\"_aposition_\"+str(array_all_a_outof1_sum[residue])+\".png\",\"wb\") \n",
    "    if np.sum(array_all_d_outof1[residue][0]) == 0.0:\n",
    "        pass\n",
    "    else:\n",
    "        aa = seqlogo.Ppm(array_all_d_outof1[residue], alphabet_type=\"AA\")\n",
    "        filename = str(residue)+\"_dposition_\"+str(array_all_d_outof1_sum[residue])+\".png\"\n",
    "        seqlogo.seqlogo(aa, ic_scale = False, format = 'png', size = 'medium', color_scheme='chemistry', \n",
    "            filename=filename, xaxis=True)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
